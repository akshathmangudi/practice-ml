{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Importance of Data Preprocessing\n\nIn this notebook, we will explore the \"Motorbike Marketplace\" dataset (link: https://www.kaggle.com/datasets/mexwell/motorbike-marketplace). However, we will stop at data preprocessing as this one of the prime examples why cleaning the data is so important. For training a machine learning model, only numerical data can be used. However, that's not always realistic and we never get numerical data. We'll explore more in detail.","metadata":{}},{"cell_type":"markdown","source":"### Step 1: Data cleaning and preprocessing\nFirst, we'll import the necessary modules that we'll use to visualize our features and convert our categorical data to numerical data.","metadata":{}},{"cell_type":"code","source":"import pandas # For CSV I/O\nimport numpy # For manipulation of pandas dataframe\nimport matplotlib.pyplot as plt # For data visualization\nimport seaborn # Also used for data visualization, specifically heatmaps and countplots.\nimport warnings\n\nseaborn.set()\nwarnings.filterwarnings('ignore')\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:48:34.312541Z","iopub.execute_input":"2023-10-01T04:48:34.312908Z","iopub.status.idle":"2023-10-01T04:48:34.321159Z","shell.execute_reply.started":"2023-10-01T04:48:34.312875Z","shell.execute_reply":"2023-10-01T04:48:34.319851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pandas.read_csv('/kaggle/input/motorbike-marketplace/europe-motorbikes-zenrows.csv')\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:45:02.729539Z","iopub.execute_input":"2023-10-01T04:45:02.729948Z","iopub.status.idle":"2023-10-01T04:45:02.816254Z","shell.execute_reply.started":"2023-10-01T04:45:02.729923Z","shell.execute_reply":"2023-10-01T04:45:02.815474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data.info() Only price, mileage and power is int64 and float64. \n# data.duplicated().sum() Count: 5832\ndata.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:45:02.817200Z","iopub.execute_input":"2023-10-01T04:45:02.817416Z","iopub.status.idle":"2023-10-01T04:45:02.833650Z","shell.execute_reply.started":"2023-10-01T04:45:02.817398Z","shell.execute_reply":"2023-10-01T04:45:02.832461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As noticed, there's a considerable portion of the data where the values are NaN. The current dataset is currently unclean as it contains NaN/missing values, redundnat features, which we'll use to get rid of.","metadata":{}},{"cell_type":"markdown","source":"## Step 2: Data Preprocessing\n\nWe will work our way around the dataset to clean the dataset. The final result, can be passed through machine learning algorithm for classification/regression purposes.","metadata":{}},{"cell_type":"code","source":"seaborn.countplot(x='fuel', data=data)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:45:02.836217Z","iopub.execute_input":"2023-10-01T04:45:02.836534Z","iopub.status.idle":"2023-10-01T04:45:03.098465Z","shell.execute_reply.started":"2023-10-01T04:45:02.836508Z","shell.execute_reply":"2023-10-01T04:45:03.097180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Filling in the NaN values of 'fuel' and 'power' with the most common value. We can assume that the majority of motorbikes use gasoline and is manual transmission","metadata":{}},{"cell_type":"code","source":"data['fuel'] = data['fuel'].fillna('Gasoline')\ndata['power'] = data['power'].replace(numpy.nan, 0)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:45:03.099503Z","iopub.execute_input":"2023-10-01T04:45:03.099766Z","iopub.status.idle":"2023-10-01T04:45:03.109233Z","shell.execute_reply.started":"2023-10-01T04:45:03.099748Z","shell.execute_reply":"2023-10-01T04:45:03.108162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seaborn.countplot(x='offer_type', data=data)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:45:03.125058Z","iopub.execute_input":"2023-10-01T04:45:03.125334Z","iopub.status.idle":"2023-10-01T04:45:03.303185Z","shell.execute_reply.started":"2023-10-01T04:45:03.125309Z","shell.execute_reply":"2023-10-01T04:45:03.302471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We still have 'gear' and 'version' to make changes to\ndata.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:45:03.304410Z","iopub.execute_input":"2023-10-01T04:45:03.304900Z","iopub.status.idle":"2023-10-01T04:45:03.323268Z","shell.execute_reply.started":"2023-10-01T04:45:03.304874Z","shell.execute_reply":"2023-10-01T04:45:03.322191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seaborn.countplot(x='gear', data=data)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:45:03.324225Z","iopub.execute_input":"2023-10-01T04:45:03.325095Z","iopub.status.idle":"2023-10-01T04:45:03.473586Z","shell.execute_reply.started":"2023-10-01T04:45:03.325069Z","shell.execute_reply":"2023-10-01T04:45:03.472766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['gear'] = data['gear'].fillna('Manual')\ndata.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:45:03.475873Z","iopub.execute_input":"2023-10-01T04:45:03.476885Z","iopub.status.idle":"2023-10-01T04:45:03.499467Z","shell.execute_reply.started":"2023-10-01T04:45:03.476854Z","shell.execute_reply":"2023-10-01T04:45:03.498898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['version'] = data['version'].replace(numpy.nan, 'None')\ndata['version']","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:45:03.500360Z","iopub.execute_input":"2023-10-01T04:45:03.500874Z","iopub.status.idle":"2023-10-01T04:45:03.510444Z","shell.execute_reply.started":"2023-10-01T04:45:03.500853Z","shell.execute_reply":"2023-10-01T04:45:03.509415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 3: Scaling and Converting the values\n\nFirst, we will perform what's known as one-hot encoding to change our cateogrical data into numerical data. Without numerical data, predictions cannot be formed. As our dataset has been cleaned, we can use standard scaling to scale our values, which will make our model training easy.  ","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder()\n\n# Transforming all our object datatype into ints\ndata['version'] = label_encoder.fit_transform(data['version'])\ndata['make_model'] = label_encoder.fit_transform(data['make_model'])\ndata['date'] = label_encoder.fit_transform(data['date'])\ndata['fuel'] = label_encoder.fit_transform(data['fuel'])\ndata['gear'] = label_encoder.fit_transform(data['gear'])\ndata['offer_type'] = label_encoder.fit_transform(data['offer_type'])\n\ndata = data.drop('link', axis=1)\ndata.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:45:03.511422Z","iopub.execute_input":"2023-10-01T04:45:03.512188Z","iopub.status.idle":"2023-10-01T04:45:03.604750Z","shell.execute_reply.started":"2023-10-01T04:45:03.512162Z","shell.execute_reply":"2023-10-01T04:45:03.603458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlation is terrible in this dataset.\ncorrelation = data.corr()\nfigure = plt.figure(figsize=(12, 10))\nseaborn.heatmap(correlation, annot=True, \n           cmap='magma', \n           fmt='.1f')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:49:13.860075Z","iopub.execute_input":"2023-10-01T04:49:13.860374Z","iopub.status.idle":"2023-10-01T04:49:14.284129Z","shell.execute_reply.started":"2023-10-01T04:49:13.860354Z","shell.execute_reply":"2023-10-01T04:49:14.283054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['power'] = data['power'].astype(numpy.int64)\ndata.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:46:34.477345Z","iopub.execute_input":"2023-10-01T04:46:34.477714Z","iopub.status.idle":"2023-10-01T04:46:34.485860Z","shell.execute_reply.started":"2023-10-01T04:46:34.477672Z","shell.execute_reply":"2023-10-01T04:46:34.484656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()\n# This is our clean dataset without standard scaling.","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:46:42.199764Z","iopub.execute_input":"2023-10-01T04:46:42.200350Z","iopub.status.idle":"2023-10-01T04:46:42.213415Z","shell.execute_reply.started":"2023-10-01T04:46:42.200326Z","shell.execute_reply":"2023-10-01T04:46:42.211821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nstd_scl = StandardScaler()\ny = data['price']\nX = data.drop('price', axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:51:48.201567Z","iopub.execute_input":"2023-10-01T04:51:48.201940Z","iopub.status.idle":"2023-10-01T04:51:48.210508Z","shell.execute_reply.started":"2023-10-01T04:51:48.201913Z","shell.execute_reply":"2023-10-01T04:51:48.209398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We've created our dependent and independent variables and we're scaling our dependent variables which will make it easy for a machine learning algoirthm to make things faster. ","metadata":{}},{"cell_type":"code","source":"X = pandas.DataFrame(std_scl.fit_transform(X))\nX.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:52:29.771504Z","iopub.execute_input":"2023-10-01T04:52:29.771897Z","iopub.status.idle":"2023-10-01T04:52:29.791397Z","shell.execute_reply.started":"2023-10-01T04:52:29.771871Z","shell.execute_reply":"2023-10-01T04:52:29.790870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Optional: Passing through a KNN\n\nNOTE: I used a machine learning algorithm that's not applicable to this dataset accurately. But here, I used a KNN to try to classify the decision boundaries between features. This didn't work and I recommend people who take this notebook for reference to stop before this step and do whatever you please. ","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:53:30.790598Z","iopub.execute_input":"2023-10-01T04:53:30.791056Z","iopub.status.idle":"2023-10-01T04:53:30.932328Z","shell.execute_reply.started":"2023-10-01T04:53:30.791023Z","shell.execute_reply":"2023-10-01T04:53:30.931207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\ntest_scores = []\ntrain_scores = []\n\nfor i in range(1, 15): \n    knn = KNeighborsClassifier(i)\n    knn.fit(X_train, y_train)\n    \n    train_scores.append(knn.score(X_train, y_train))\n    test_scores.append(knn.score(X_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:54:28.862374Z","iopub.execute_input":"2023-10-01T04:54:28.862711Z","iopub.status.idle":"2023-10-01T04:56:15.690854Z","shell.execute_reply.started":"2023-10-01T04:54:28.862664Z","shell.execute_reply":"2023-10-01T04:56:15.689396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_train = max(train_scores)\n\ntrain_score = [i for i, v in enumerate(train_scores) if v == max_train]\nprint(f\"Max train score {max_train * 100}% and k = {list(map(lambda x: x + 1, train_score))}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:56:15.692887Z","iopub.execute_input":"2023-10-01T04:56:15.693214Z","iopub.status.idle":"2023-10-01T04:56:15.700069Z","shell.execute_reply.started":"2023-10-01T04:56:15.693189Z","shell.execute_reply":"2023-10-01T04:56:15.698767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_test = max(test_scores)\n\ntest_score = [i for i, v in enumerate(test_scores) if v == max_test]\nprint(f\"Max est score {max_test * 100}% and k = {list(map(lambda x: x + 1, test_score))}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:56:28.492501Z","iopub.execute_input":"2023-10-01T04:56:28.493032Z","iopub.status.idle":"2023-10-01T04:56:28.499098Z","shell.execute_reply.started":"2023-10-01T04:56:28.492992Z","shell.execute_reply":"2023-10-01T04:56:28.498204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### And we're done!\n\nHere, we only stopped till data cleaning. Data preprocessing is one of the msot important steps in training machine/deep learning model and here I've employed an example of that. Using one-hot encoding, we'll transform our categorical data into numerical and fill in the missing values. If there any questions or if you'd like to collab with me, send me a mail at akshathmangudi@gmail.com. \n\nNotebook by Akshath Mangudi","metadata":{}}]}