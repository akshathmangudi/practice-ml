{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Used Car Prediction\n\nIn this notebook, we will explore the \"Used Car Price Prediction\" dataset (link: https://www.kaggle.com/datasets/taeefnajib/used-car-price-prediction-dataset) and apply the \"Support Vector Regression\" algorithm to this dataset. Support Vector Regression, or SVR for short, is similar to Support Vector Classifier, where SVC is used for classification purposes (my previous notebook: Breast Cancer Prediction), and SVR is used for regression purposes. \n\nHere we will try to find the best fit for the given dataset which can be accurately predicted under a given test scenario. ","metadata":{}},{"cell_type":"markdown","source":"### Step 1: Data cleaning and Preprocessing\n\nWe will first import the necessary modules and convert any categorical data to numerical as well as filling in NaN values.","metadata":{}},{"cell_type":"code","source":"import pandas as pd # For CSV I/O\nimport numpy as np  # For manipulation of pandas dataframe.\nimport seaborn as sns # For visualizing data between dependent variable(s)\nimport matplotlib.pyplot as plt # For comparing multiple dependent variables.","metadata":{"execution":{"iopub.status.busy":"2023-09-23T06:41:23.060820Z","iopub.execute_input":"2023-09-23T06:41:23.061220Z","iopub.status.idle":"2023-09-23T06:41:24.947208Z","shell.execute_reply.started":"2023-09-23T06:41:23.061185Z","shell.execute_reply":"2023-09-23T06:41:24.945955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/used-car-price-prediction-dataset/used_cars.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T06:41:24.949331Z","iopub.execute_input":"2023-09-23T06:41:24.949880Z","iopub.status.idle":"2023-09-23T06:41:25.021664Z","shell.execute_reply.started":"2023-09-23T06:41:24.949840Z","shell.execute_reply":"2023-09-23T06:41:25.020537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df.info() Everything is of object type except \"model_year\"\n# df.duplicated().sum() Returns zero.\ndf.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T06:41:25.023232Z","iopub.execute_input":"2023-09-23T06:41:25.023568Z","iopub.status.idle":"2023-09-23T06:41:25.038611Z","shell.execute_reply.started":"2023-09-23T06:41:25.023540Z","shell.execute_reply":"2023-09-23T06:41:25.037627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As noticed above, in three of the dependent variables, there are a decent number of NaN/zero values that must be fixed. But before that, we have to change all our categorical data, which is what this dataset consists of, and convert into numerical data. ","metadata":{}},{"cell_type":"code","source":"# Changing categorical data. \nfrom sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder()\n\ndf['brand'] = label_encoder.fit_transform(df['brand'])\ndf.head() # Brand name changed to numbers.","metadata":{"execution":{"iopub.status.busy":"2023-09-23T06:41:25.040871Z","iopub.execute_input":"2023-09-23T06:41:25.041235Z","iopub.status.idle":"2023-09-23T06:41:25.210684Z","shell.execute_reply.started":"2023-09-23T06:41:25.041198Z","shell.execute_reply":"2023-09-23T06:41:25.209789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Creating new features mileage_int and price_int by replace mi and $ as well as any commas for\nnumerical data conversion.","metadata":{}},{"cell_type":"code","source":"# Function for replacing symbols and changing to numerical data. \n\ndef return_mileage(s): \n    mileage = int((s.replace(',','')).replace('mi.',''))\n    return mileage\n\ndef return_price(s): \n    price = int((s.replace(',','')).replace('$',''))\n    return price","metadata":{"execution":{"iopub.status.busy":"2023-09-23T06:41:25.212108Z","iopub.execute_input":"2023-09-23T06:41:25.212660Z","iopub.status.idle":"2023-09-23T06:41:25.217723Z","shell.execute_reply.started":"2023-09-23T06:41:25.212630Z","shell.execute_reply":"2023-09-23T06:41:25.216961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['mileage_int'] = df['milage'].map(return_mileage)\ndf.drop('milage', axis=1, inplace=True)\n\ndf['price_int'] = df['price'].map(return_price)\ndf.drop('price', axis=1, inplace=True)\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T06:41:25.218893Z","iopub.execute_input":"2023-09-23T06:41:25.219371Z","iopub.status.idle":"2023-09-23T06:41:25.264598Z","shell.execute_reply.started":"2023-09-23T06:41:25.219343Z","shell.execute_reply":"2023-09-23T06:41:25.263373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we repalce the NaN values of \"accident\", \"fuel_type\" and \"clean_title\"","metadata":{}},{"cell_type":"code","source":"# Using .replace to replace the NaN values.\ndf['accident'] = df['accident'].replace(\n    {\n        'At least 1 accident or damage reported': 'Yes',\n        'None reported': 'No'\n    }\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T06:41:25.267362Z","iopub.execute_input":"2023-09-23T06:41:25.268055Z","iopub.status.idle":"2023-09-23T06:41:25.276287Z","shell.execute_reply.started":"2023-09-23T06:41:25.268014Z","shell.execute_reply":"2023-09-23T06:41:25.275244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df['fuel_type'].value_counts() 2 counts of \"not supported\", 45 counts of \"-\"\nsns.countplot(x='fuel_type', data=df)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T06:41:25.277767Z","iopub.execute_input":"2023-09-23T06:41:25.278559Z","iopub.status.idle":"2023-09-23T06:41:25.605341Z","shell.execute_reply.started":"2023-09-23T06:41:25.278525Z","shell.execute_reply":"2023-09-23T06:41:25.604266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['fuel_type'] = df['fuel_type'].fillna('Gasoline')\ndf['fuel_type'] = df['fuel_type'].replace(\n    {\n        '-': 'Hybrid',\n        'not supported': 'Hybrid'\n    }\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T06:41:25.606528Z","iopub.execute_input":"2023-09-23T06:41:25.606945Z","iopub.status.idle":"2023-09-23T06:41:25.616683Z","shell.execute_reply.started":"2023-09-23T06:41:25.606904Z","shell.execute_reply":"2023-09-23T06:41:25.615388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['clean_title'] = df['clean_title'].fillna('No')","metadata":{"execution":{"iopub.status.busy":"2023-09-23T06:41:25.622373Z","iopub.execute_input":"2023-09-23T06:41:25.622797Z","iopub.status.idle":"2023-09-23T06:41:25.630233Z","shell.execute_reply.started":"2023-09-23T06:41:25.622766Z","shell.execute_reply":"2023-09-23T06:41:25.629225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have achieved two things: \n1. Adding new features to change them into numerical data (mileage/price)\n2. Filling in zero values with non-zero equivalents. \n\nHowever, the majority of the data is still in \"object\" type, and we need to convert them into numerical data. We can use LabelEncoder().fit_transform() to achieve this task. The following implementation is done below","metadata":{}},{"cell_type":"code","source":"df['accident']=label_encoder.fit_transform(df['accident'])\ndf['fuel_type']=label_encoder.fit_transform(df['fuel_type'])\n\ndf['ext_col'] = label_encoder.fit_transform(df['ext_col'])\ndf['int_col'] = label_encoder.fit_transform(df['int_col'])\ndf['transmission'] = label_encoder.fit_transform(df['transmission'])\ndf['engine'] = label_encoder.fit_transform(df['engine'])\ndf['model'] = label_encoder.fit_transform(df['model'])\ndf['clean_title'] = label_encoder.fit_transform(df['clean_title'])","metadata":{"execution":{"iopub.status.busy":"2023-09-23T06:41:25.631483Z","iopub.execute_input":"2023-09-23T06:41:25.631861Z","iopub.status.idle":"2023-09-23T06:41:25.666917Z","shell.execute_reply.started":"2023-09-23T06:41:25.631830Z","shell.execute_reply":"2023-09-23T06:41:25.665973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()\n\n# Converted everything to numerical data.","metadata":{"execution":{"iopub.status.busy":"2023-09-23T06:41:25.668244Z","iopub.execute_input":"2023-09-23T06:41:25.668650Z","iopub.status.idle":"2023-09-23T06:41:25.692067Z","shell.execute_reply.started":"2023-09-23T06:41:25.668613Z","shell.execute_reply":"2023-09-23T06:41:25.690950Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 2: Splitting the dataset.\n\nHere, we split the dataset into independent and dependent variables for SVR training.","metadata":{}},{"cell_type":"code","source":"X = df.drop('price_int', axis=1)\ny = df['price_int']\n\nX.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T06:41:25.694035Z","iopub.execute_input":"2023-09-23T06:41:25.694866Z","iopub.status.idle":"2023-09-23T06:41:25.713723Z","shell.execute_reply.started":"2023-09-23T06:41:25.694823Z","shell.execute_reply":"2023-09-23T06:41:25.712431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T06:41:25.715306Z","iopub.execute_input":"2023-09-23T06:41:25.715710Z","iopub.status.idle":"2023-09-23T06:41:25.728388Z","shell.execute_reply.started":"2023-09-23T06:41:25.715680Z","shell.execute_reply":"2023-09-23T06:41:25.727451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score\nfrom sklearn.svm import SVR","metadata":{"execution":{"iopub.status.busy":"2023-09-23T06:41:25.730140Z","iopub.execute_input":"2023-09-23T06:41:25.730737Z","iopub.status.idle":"2023-09-23T06:41:25.946766Z","shell.execute_reply.started":"2023-09-23T06:41:25.730694Z","shell.execute_reply":"2023-09-23T06:41:25.945624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"NOTE: I had used StandardScaler in order to speed up the steps that I will go into detail below, however that's not a healthy practice under this scenario as all my columns where changed into indices which had to be mapped to their previous column names. I have commented out the StandardScaler code, and the result is still accurate. ","metadata":{}},{"cell_type":"code","source":"X = StandardScaler().fit_transform(X)\nX = pd.DataFrame(X)\nX.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T06:41:25.948255Z","iopub.execute_input":"2023-09-23T06:41:25.948882Z","iopub.status.idle":"2023-09-23T06:41:25.972751Z","shell.execute_reply.started":"2023-09-23T06:41:25.948847Z","shell.execute_reply":"2023-09-23T06:41:25.971644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 3: Finding our best parameters and splitting the dataset (part 2)\n\nHere, we will use train_test_split to split the dataset into training and testing data and also using StratifiedKFold() to split the dataset into 5 parts which will then be used for test C, gamma, and kernel values to find the best parameters for our model.\n \nThis will then be used in our SVR and be tested using our test data.","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\ncv = StratifiedKFold(n_splits=3, shuffle=True, random_state=164)\n\nsvr = SVR()\nsvr_args = {\n    'C': [0.01, 0.1, 1, 10, 100],\n    'gamma': [1, 0.1, 0.05, 0.01, 0.001],\n    'kernel': ['rbf', 'poly', 'sigmoid']\n}\n\nbest_params = GridSearchCV(estimator = svr, \n                           param_grid = svr_args, \n                           cv = cv,\n                           verbose = 1,\n                           scoring = 'neg_mean_squared_error')\n\nresult_svr = best_params.fit(X_train, y_train)\nresult_svr.best_params_","metadata":{"execution":{"iopub.status.busy":"2023-09-23T06:51:01.002930Z","iopub.execute_input":"2023-09-23T06:51:01.003355Z","iopub.status.idle":"2023-09-23T06:53:16.299872Z","shell.execute_reply.started":"2023-09-23T06:51:01.003323Z","shell.execute_reply":"2023-09-23T06:53:16.298690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 4: Model Training\n\nThe results of the GridSearch were: \n- C: 0.01\n- gamma: 1\n- kernel: rbf (radial basis function)\n\nNow, we will use these parameters and train our SVR, this will then be plotted against the true data y and a line will be produced to show the line of best fit. ","metadata":{}},{"cell_type":"code","source":"svr = svr.set_params(**result_svr.best_params_)\nsvr.fit(X_train, y_train)\n\nprediction = svr.predict(X_test)\n\nplt.figure(figsize=(16, 8))\nplt.scatter(X[10], y, color='darkorange', label='Data') # 10 corresponds to 'mileage_int'\nplt.plot(X_test, prediction, color='navy', lw=2, label=\"rbf\")\nplt.xlabel('Input')\nplt.ylabel('Output')\nplt.title('SVR for predicting used car prices')\nplt.legend()\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-23T06:54:00.616963Z","iopub.execute_input":"2023-09-23T06:54:00.618089Z","iopub.status.idle":"2023-09-23T06:54:02.700848Z","shell.execute_reply.started":"2023-09-23T06:54:00.618049Z","shell.execute_reply":"2023-09-23T06:54:02.698978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We have completed our model training! \n\nThe line generated above (navy) shows the least error from our SVR algorithm and this is the line of best fit to the dataset above. If there are any questions or if you would like to collab with me on a project, please send me a mail at akshathmangudi@gmail.com. Good day. \n\nNotebook by Akshath Mangudi","metadata":{}}]}